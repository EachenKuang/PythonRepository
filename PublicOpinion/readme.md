# 这是用于Data啊Fountain的《基于主题的文本情感分析》的思路分析

## 赛题背景
近年来，文本情感分析技术在网络营销、企业舆情监控、政府舆论监控等扮演越来越重要的角色。鉴于主题模型在文本挖掘领域的优势，基于主题的文本情感分析技术也成为人们关注的热点，其主要任务是通过挖掘用户评论所蕴含的主题、以及对这些主题的情感偏好，来提高文本情感分析的性能。以网上电商购物评论为例，原始的主题模型主要针对篇幅较大的文档或者评论句子的集合，学习到的主题主要针对整个产品品牌；而现实情形是，用户评论大多针围绕产品的某些特征或内容主题展开（如口味、服务、环境、性价比、交通、快递、内存、电池续航能力、原料、保质期等等，这说明相比于对产品的整体评分， 用户往往更关心产品特征），而且评论文本往往较短。
## 任务描述
本次大赛提供脱敏后的电商评论数据。参赛队伍需要通过数据挖掘的技术和机器学习的算法，根据语句中的主题特征和情感信息来分析用户对这些主题的偏好，并以<主题，情感词>序对作为输出。
## 分词工具
StanfordCoreNLP
结巴分词

## 数据结构
| row_id | content-评论内容 | theme-主题 | sentiment_word-情感关键词	 | sentiment_anls-情感正负面 |
| ---- | ---- | ---- | ---- | ---- |
|1|2|3|4|5|



## 模型思路
### 基于情感词库的情感分析
1. 建立情感词库，使用训练数据集（20000条）
2. 读取评论数据，对评论进行分词
3. 抽取情感词，记录词的位置
  * 直接从分词中抽取情感词库中含有的词
  * 记录词的位置
4. 匹配情感词对应的主题词（可能存在没有主题词的情况）
  * 根据情感词的标注词性来寻找主题词
  * 使用标点来隔开句子
5. 利用已有的情感词库进行标注

* 优点：
  1. 拟合程度较高
  2. 方法简单易实现
* 缺点
  1. 过分依赖于训练集，当训练集比较小的时候正确性较低
  2. 

# 模型步骤
利用结巴分词学习训练词典
情感词典的构建



## 难点
1. 斯坦福分词工具分的词过于细
2. 抽取主题词，与之对应的情感词以及情感分析

## 需要解决的问题

1. **（解决）** 对于 ‘次’这个词的错误划分  
第三次买了，很实用的灯！！！！,买了;灯;,次;实用;,-1;1;
‘次’应该作为次数，而不应该出现在感情词中。
2. 对于否定副词需要添加时识别  
14644,沾水会生锈，不开心。,NULL;,开心;,1;
3. **（解决）** content中存在英文逗号，会对分析结果造成影响

